{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt_sismo</th>\n",
       "      <th>fecha_sismo</th>\n",
       "      <th>hora_sismo</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>profundidad</th>\n",
       "      <th>mag</th>\n",
       "      <th>ubicacion</th>\n",
       "      <th>pais</th>\n",
       "      <th>peligrosidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01 18:50:43+00:00</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>18:50:43</td>\n",
       "      <td>-26.913</td>\n",
       "      <td>-71.105</td>\n",
       "      <td>45.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>91 km WNW of Copiapó, Chile</td>\n",
       "      <td>Chile</td>\n",
       "      <td>moderado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01 21:58:16+00:00</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>21:58:16</td>\n",
       "      <td>-34.920</td>\n",
       "      <td>-72.759</td>\n",
       "      <td>34.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>55 km NW of Constitución, Chile</td>\n",
       "      <td>Chile</td>\n",
       "      <td>moderado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-03 21:50:22+00:00</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>21:50:22</td>\n",
       "      <td>-36.994</td>\n",
       "      <td>-74.084</td>\n",
       "      <td>25.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>73 km WNW of Arauco, Chile</td>\n",
       "      <td>Chile</td>\n",
       "      <td>moderado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-05 00:54:31+00:00</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>00:54:31</td>\n",
       "      <td>-45.992</td>\n",
       "      <td>-76.472</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>290 km W of Puerto Chacabuco, Chile</td>\n",
       "      <td>Chile</td>\n",
       "      <td>fuerte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-05 09:17:35+00:00</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>09:17:35</td>\n",
       "      <td>-27.921</td>\n",
       "      <td>-71.143</td>\n",
       "      <td>45.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>81 km NNW of Vallenar, Chile</td>\n",
       "      <td>Chile</td>\n",
       "      <td>moderado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    dt_sismo fecha_sismo hora_sismo  latitude  longitude  \\\n",
       "0  2012-01-01 18:50:43+00:00  2012-01-01   18:50:43   -26.913    -71.105   \n",
       "1  2012-01-01 21:58:16+00:00  2012-01-01   21:58:16   -34.920    -72.759   \n",
       "2  2012-01-03 21:50:22+00:00  2012-01-03   21:50:22   -36.994    -74.084   \n",
       "3  2012-01-05 00:54:31+00:00  2012-01-05   00:54:31   -45.992    -76.472   \n",
       "4  2012-01-05 09:17:35+00:00  2012-01-05   09:17:35   -27.921    -71.143   \n",
       "\n",
       "   profundidad  mag                            ubicacion   pais peligrosidad  \n",
       "0         45.2  4.6          91 km WNW of Copiapó, Chile  Chile     moderado  \n",
       "1         34.7  4.1      55 km NW of Constitución, Chile  Chile     moderado  \n",
       "2         25.1  4.6           73 km WNW of Arauco, Chile  Chile     moderado  \n",
       "3         10.0  5.3  290 km W of Puerto Chacabuco, Chile  Chile       fuerte  \n",
       "4         45.8  4.6         81 km NNW of Vallenar, Chile  Chile     moderado  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Especifica la ruta y nombre del archivo CSV\n",
    "archivo_csv = \"combined_earthquake_data.csv\"\n",
    "\n",
    "# Lee el archivo CSV con pandas\n",
    "df = pd.read_csv(archivo_csv)\n",
    "\n",
    "# Muestra el contenido del DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "peligrosidad\n",
       "moderado      24535\n",
       "leve           2725\n",
       "fuerte         1128\n",
       "muy fuerte       10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtiene los distintos tipos de valores y sus conteos en la columna \"peligrosidad\"\n",
    "conteo_valores = df[\"peligrosidad\"].value_counts()\n",
    "conteo_valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir el conjunto de datos en características (X) y variable objetivo (y)\n",
    "X = df[['mag', 'profundidad']]  # Características\n",
    "y = df[\"peligrosidad\"]  # Variable objetivo\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (proporción 80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Crear una instancia del modelo de Bosque Aleatorio\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Entrenar el modelo utilizando el conjunto de entrenamiento\n",
    "rf_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 1.0\n",
      "Recall: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      fuerte       1.00      1.00      1.00       208\n",
      "        leve       1.00      1.00      1.00       549\n",
      "    moderado       1.00      1.00      1.00      4920\n",
      "  muy fuerte       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00      5680\n",
      "   macro avg       1.00      1.00      1.00      5680\n",
      "weighted avg       1.00      1.00      1.00      5680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión:\", accuracy)\n",
    "\n",
    "# Calcular el recall del modelo\n",
    "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# Evaluar el rendimiento del modelo\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_train: (17038, 2)\n",
      "Forma de y_train: (17038,)\n",
      "Forma de X_val: (5680, 2)\n",
      "Forma de y_val: (5680,)\n",
      "Forma de X_test: (5680, 2)\n",
      "Forma de y_test: (5680,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir el conjunto de datos en características (X) y variable objetivo (y)\n",
    "X = df[['mag', 'profundidad']]  # Características\n",
    "y = df[\"peligrosidad\"]  # Variable objetivo\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (proporción 80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dividir el conjunto de entrenamiento en conjuntos de entrenamiento y validación (proporción 75:25)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Imprimir las formas de los conjuntos de datos resultantes\n",
    "print(\"Forma de X_train:\", X_train.shape)\n",
    "print(\"Forma de y_train:\", y_train.shape)\n",
    "print(\"Forma de X_val:\", X_val.shape)\n",
    "print(\"Forma de y_val:\", y_val.shape)\n",
    "print(\"Forma de X_test:\", X_test.shape)\n",
    "print(\"Forma de y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 1.0\n",
      "Recall: 1.0\n",
      "Informe de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      fuerte       1.00      1.00      1.00       208\n",
      "        leve       1.00      1.00      1.00       549\n",
      "    moderado       1.00      1.00      1.00      4920\n",
      "  muy fuerte       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00      5680\n",
      "   macro avg       1.00      1.00      1.00      5680\n",
      "weighted avg       1.00      1.00      1.00      5680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, classification_report\n",
    "\n",
    "# Crear una instancia del modelo de Bosque Aleatorio\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Entrenar el modelo utilizando el conjunto de entrenamiento\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión:\", accuracy)\n",
    "\n",
    "# Calcular el recall del modelo\n",
    "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Evaluar el rendimiento del modelo utilizando el informe de clasificación\n",
    "classification_report = classification_report(y_test, y_pred)\n",
    "print(\"Informe de clasificación:\\n\", classification_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validación cruzada utilizando k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación cruzada:\n",
      "Precisión promedio: 0.9996478184240951\n",
      "Desviación estándar de precisión: 0.0002875550594707632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Crear una instancia del modelo de Bosque Aleatorio\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Aplicar k-fold cross-validation con 5 folds\n",
    "scores = cross_val_score(rf_model, X_train, y_train, cv=5) # Asegúrate de ajustar el número de folds (cv) según tus necesidades. Cuanto mayor sea el número de folds, más robusta será la evaluación, pero también aumentará el tiempo de ejecución.\n",
    "\n",
    "# Imprimir los resultados de validación cruzada\n",
    "print(\"Resultados de validación cruzada:\")\n",
    "print(\"Precisión promedio:\", scores.mean())\n",
    "print(\"Desviación estándar de precisión:\", scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de la validación cruzada muestra una precisión promedio de aproximadamente 0.9996 y una desviación estándar de precisión de aproximadamente 0.0003. Esto indica que el modelo de Bosque Aleatorio tiene un rendimiento consistente y preciso en diferentes divisiones de los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código para SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Cargar el dataset\n",
    "# df = pd.read_csv(\"combined_earthquake_data.csv\")\n",
    "\n",
    "# # Seleccionar las características (magnitud y profundidad) y la variable objetivo (peligrosidad)\n",
    "# X = df[['mag', 'profundidad']]\n",
    "# y = df['peligrosidad']\n",
    "\n",
    "# # Normalizar las características\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# # Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Crear y entrenar el modelo de SVM\n",
    "# model_svm = SVC(random_state=42)\n",
    "# model_svm.fit(X_train, y_train)\n",
    "\n",
    "# # Realizar predicciones en el conjunto de prueba\n",
    "# y_pred = model_svm.predict(X_test)\n",
    "\n",
    "# # Evaluar el rendimiento del modelo\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
